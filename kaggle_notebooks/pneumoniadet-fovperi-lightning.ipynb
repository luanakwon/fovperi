{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10338,"databundleVersionId":862042,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightning","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overview of data distribution\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport pydicom\n\ntrain_labels = pd.read_csv('/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv')\n\n#-------------------------------\nprint('Target distribution')\nn_zeros = len(train_labels[train_labels['Target']==0])\nn_ones = len(train_labels[train_labels['Target']==1])\nn_else = len(train_labels)-n_zeros-n_ones\nprint(f\"Ones: {n_ones}, Zeros: {n_zeros}, else: {n_else}\")\n\n#------------------------------\nprint('bounding box position distribution')\nbboxes = train_labels[['x','y','width','height']].dropna()\nx_info = {\n    'min': np.min(bboxes['x']),\n    'mean': np.mean(bboxes['x']),\n    'max': np.max(bboxes['x']),\n    'std': np.std(bboxes['x'])\n}\ny_info = {\n    'min': np.min(bboxes['y']),\n    'mean': np.mean(bboxes['y']),\n    'max': np.max(bboxes['y']),\n    'std': np.std(bboxes['y'])\n}\nw_info = {\n    'min': np.min(bboxes['width']),\n    'mean': np.mean(bboxes['width']),\n    'max': np.max(bboxes['width']),\n    'std': np.std(bboxes['width'])\n}\nh_info = {\n    'min': np.min(bboxes['height']),\n    'mean': np.mean(bboxes['height']),\n    'max': np.max(bboxes['height']),\n    'std': np.std(bboxes['height'])\n}\nprint(f\"bbox x distribution - {x_info}\")\nprint(f\"bbox y distribution - {y_info}\")\nprint(f\"bbox w distribution - {w_info}\")\nprint(f\"bbox h distribution - {h_info}\")\n\n#-----------------------------\nprint('pixel data distribution')\npatient100 = train_labels['patientId'].sample(100)\np_info = {'min':1e+10,'mean':0,'max':0,'std':0}\nfor pid in patient100:\n    dcm_root_path = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images'\n    dcm_path = os.path.join(dcm_root_path,f'{pid}.dcm')\n    img = pydicom.read_file(dcm_path).pixel_array\n    p_info['min'] = min(p_info['min'],np.min(img))\n    p_info['mean'] += np.mean(img)\n    p_info['max'] = max(p_info['max'],np.max(img))\n    p_info['std'] += np.std(img)\n    \np_info['mean'] /= 100\np_info['std'] /= 100\n\nprint(f\"pixel value distribution - {p_info}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-24T07:11:37.299151Z","iopub.execute_input":"2024-05-24T07:11:37.299576Z","iopub.status.idle":"2024-05-24T07:11:39.564771Z","shell.execute_reply.started":"2024-05-24T07:11:37.299546Z","shell.execute_reply":"2024-05-24T07:11:39.563469Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Target distribution\nOnes: 9555, Zeros: 20672, else: 0\nbounding box position distribution\nbbox x distribution - {'min': 2.0, 'mean': 394.04772370486654, 'max': 835.0, 'std': 204.56346707193563}\nbbox y distribution - {'min': 2.0, 'mean': 366.83956043956044, 'max': 881.0, 'std': 148.93269371624748}\nbbox w distribution - {'min': 40.0, 'mean': 218.4713762428048, 'max': 528.0, 'std': 59.28637267069208}\nbbox h distribution - {'min': 45.0, 'mean': 329.2697017268446, 'max': 942.0, 'std': 157.7424995927731}\npixel data distribution\npixel value distribution - {'min': 0, 'mean': 126.79892159461976, 'max': 255, 'std': 57.961084378973744}\n","output_type":"stream"}]},{"cell_type":"code","source":"import lightning as L\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.transforms import functional as F\n\n\nclass CustomTransform(nn.Module):\n    # totensor\n    # random horizontal flip\n    # random crop\n    # normalize\n    def __init__(self, size, random=True):\n        self.size = size\n        self.p = 0.5\n        self.mean = 126\n        self.std = 57\n        self.random=random\n        \n    def forward(self, data):\n        # split image and bbox label\n        img, bbox = data\n        width = img.shape[-1]\n        # numpy to tensor\n        img = torch.from_numpy(img, dtype=torch.float32)\n        if self.random:\n            # random horizontal flip\n            if torch.rand(1) < self.p:\n                img = F.hflip(img)\n                bbox[0] = width-bbox[0]-bbox[2]\n            # random crop (did not implement padding)\n            i, j, h, w = transforms.RandomCrop.get_params(img, self.size)\n            img = F.crop(img,i,j,h,w)\n            bbox[0] = bbox[0] - j if bbox[0] > j else 0\n            bbox[1] = bbox[1] - i if bbox[1] > i else 0\n            bbox[2] = w-bbox[0]-1 if bbox[0]+bbox[2] >= w else bbox[2]\n            bbox[3] = h-bbox[1]-1 if bbox[1]+bbox[3] >= h else bbox[3]\n        # normalize\n        img = F.normalize(img, self.mean, self.std)\n        \n        return img, bbox\n    \n    def __repr__(self):\n        out = \"Custom Transform to transform both the image and the bbox\\n\"\n        out += \"\\ttorch.from_numpy()\\n\"\n        if self.random:\n            out += f\"\\tRandomHorizontalFlip(p={self.p})\\n\"\n            out += f\"\\tRandomCrop({self.size}, padding=False)\\n\"\n        out += f\"\\tNormalize(mean={self.mean},std={self.std})\"\n        return out\n        \n        \nclass CustomDataset(Dataset):\n    def __init__(self, root, df, transform):\n        super(MyDataset).__init__()\n        self.root = root\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        # dtype of float32 implemented only\n        # convert bbox to tensor\n        bbox = torch.Tensor(row[1:5], dtype=torch.float32)\n        label = torch.Tensor(row[5], dtype=torch.float32)\n        \n        pid = row[0]\n        dcm_path = os.path.join(self.root,f'{pid}.dcm')\n        img = pydicom.read_file(dcm_path).pixel_array\n        \n        img, bbox = self.transform((img,bbox))\n        \n        return pid, img, bbox, label\n        \n    \n\nclass PDCDataModule(L.LightningDataModule):\n    def __init__(self, data_dir='./', batch_size=1,num_workers=0):\n        super().__init__()\n        self.data_dir = data_dir\n        if isinstance(batch_size,int):\n            self.tr_batch_size=batch_size\n            self.val_batch_size=batch_size\n        elif len(batch_size) == 2:\n            self.tr_batch_size=batch_size[0]\n            self.val_batch_size=batch_size[1]\n        else:\n            raise ValueError(batch_size) \n        self.num_workers=num_workers\n        \n    def prepare_data(self, fold=0, random_seed=42)\n        # read full dataframe\n        full_df = pd.read_csv(os.path.join(\n            self.data_dir,'stage_2_train_labels.csv'))\n        df_0 = full_df[full_df['Target']==0]\n        df_1 = full_df[full_df['Target']==1]\n        # apply undersampling to target==0\n        df_00 = df_0.sample(frac=0.25,random_state=random_seed)\n        df_01 = df_0.drop(df_00.index).sample(n=len(df_00),random_state=random_seed)\n        df_10 = df_1.sample(frac=0.5,random_state=random_seed)\n        df_11 = df_1.drop(df_10.index)\n        # Train Test Split: split the dataframe\n        if fold == 0:\n            self.tr_df = pd.concat((df_00,df_10))\n            self.val_df = pd.concat((df_01,df_11))\n        elif fold == 1:\n            self.tr_df = pd.concat((df_01,df_11))\n            self.val_df = pd.concat((df_00,df_10))\n        else:\n            raise ValueError('fold should be either 0 or 1')\n        \n    def setup(self, size):\n        self.tr_dset = CustomDataset(\n            root=os.path.join(self.data_dir,'stage_2_train_images'),\n            df=self.tr_df,\n            transform=CustomTransform(size))\n        self.val_dset = CustomDataset(\n            root=os.path.join(self.data_dir,'stage_2_train_images'),\n            df=self.val_df,\n            transform=CustomTransform(size, random=False))\n    \n    def train_dataloader(self):\n        return DataLoader(\n                    dataset=self.tr_dset, \n                    batch_size=self.tr_batch_size, \n                    suffle=True, num_workers=self.num_workers)\n    def val_dataloader(self):\n        return DataLoader(\n                    dataset=self.val_dset, \n                    batch_size=self.val_batch_size, \n                    shuffle=False, num_workers=self.num_workers)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:52:35.988070Z","iopub.execute_input":"2024-05-24T10:52:35.988658Z","iopub.status.idle":"2024-05-24T10:52:36.049425Z","shell.execute_reply.started":"2024-05-24T10:52:35.988627Z","shell.execute_reply":"2024-05-24T10:52:36.047943Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    from torchvision.transforms.functional as F\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (2449199879.py, line 7)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}